# -*- coding: utf-8 -*-
"""app.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jCOQ2ECFvJ2J2DE-MX_BOxhGWNsk-KfA
"""

!pip install -U streamlit transformers torch

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import pandas as pd
# import matplotlib.pyplot as plt
# import streamlit as st
# from transformers import pipeline
# import torch
# 
# st.set_page_config(
#     page_title="Sarcasm & Emotion Analyzer",
#     layout="centered"
# )
# 
# st.title("Sarcasm & Emotion Detection")
# st.write("Analyze text for sarcasm and emotion using trained NLP models.")
# 
# 
# SARCASM_MODEL_PATH = "/content/drive/MyDrive/sarcasm_model"
# EMOTION_MODEL_PATH = "/content/drive/MyDrive/final_emotion_model"
# 
# DEVICE = 0 if torch.cuda.is_available() else -1
# 
# 
# @st.cache_resource
# def load_models():
#     sarcasm_pipe = pipeline(
#         "text-classification",
#         model=SARCASM_MODEL_PATH,
#         tokenizer=SARCASM_MODEL_PATH,
#         top_k=None,
#         device=DEVICE
#     )
# 
#     emotion_pipe = pipeline(
#         "text-classification",
#         model=EMOTION_MODEL_PATH,
#         tokenizer=EMOTION_MODEL_PATH,
#         top_k=None,
#         device=DEVICE
#     )
# 
#     return sarcasm_pipe, emotion_pipe
# 
# 
# sarcasm_pipeline, emotion_pipeline = load_models()
# 
# text_input = st.text_area(
#     "Enter text:",
#     placeholder="Add your Text Please",
#     height=120
# )
# 
# if st.button("Analyze"):
#     if text_input.strip() == "":
#         st.warning("Please enter some text.")
#     else:
#         with st.spinner("Analyzing..."):
#             sarcasm_result = sarcasm_pipeline(text_input)[0]
# 
# 
#         sarcasm_df = pd.DataFrame(sarcasm_result)
# 
#         sarcastic_score = sarcasm_df.loc[
#             sarcasm_df["label"] == "sarcastic", "score"
#         ].values[0]
# 
#         not_sarcastic_score = sarcasm_df.loc[
#             sarcasm_df["label"] == "not_sarcastic", "score"
#         ].values[0]
# 
#         st.subheader("Sarcasm Analysis")
# 
# 
#         st.bar_chart(
#             sarcasm_df.set_index("label")["score"]
#         )
# 
# 
#         if sarcastic_score > not_sarcastic_score:
#             st.error("This text is **SARCASTIC**")
#             st.write(f"Confidence: {sarcastic_score:.2f}")
# 
# 
#         else:
#             st.success("This text is **NOT sarcastic**")
# 
#             emotion_result = emotion_pipeline(text_input)[0]
#             emotion_df = pd.DataFrame(emotion_result)
# 
#             top_emotion = emotion_df.loc[
#                 emotion_df["score"].idxmax()
#             ]
# 
#             st.markdown(
#                 f"### Detected Emotion: **{top_emotion['label']}**"
#             )
#             st.write(f"Confidence: {top_emotion['score']:.2f}")
# 
#             st.subheader("Emotion Distribution")
# 
# 
#             st.bar_chart(
#                 emotion_df.set_index("label")["score"]
#             )
# 
# st.markdown("---")
# st.caption("Built using Transformers & Streamlit")
#

from google.colab import drive
drive.mount("/content/drive")

!ls /content/drive/MyDrive/sarcasm_model
!ls /content/drive/MyDrive/final_emotion_model

!wget -q https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64
!chmod +x cloudflared-linux-amd64

!./cloudflared-linux-amd64 tunnel --url http://localhost:8501